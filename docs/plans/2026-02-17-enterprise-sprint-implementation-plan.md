# Enterprise Sprint Implementation Plan â€” Current Sprint

> **Move 2: Strategic Planning** | Confidence: 92% | Quality Gate: âœ… PASSED
> 
> Based on Orchestrator Directives from 2026-02-17

---

## Orchestrator Directives (Locked)

| # | Decision | Directive |
|---|----------|-----------|
| 1 | Search Strategy | Edge N-gram + Synonym Map (NO custom BM25) |
| 2 | Re-ranking | Lex Specialis ONLY (ML re-ranker DEFERRED) |
| 3 | Sprint Scope | Hybrid Search + Query Rewriter + Disambiguation + Citation Backend |

---

## Data Flow After Upgrade

```mermaid
graph TD
    A[User Query] --> C{Has History?}
    C -->|Yes| D[QUERY REWRITER]
    C -->|No| E[Original Query]
    D --> F[CLASSIFIERS]
    E --> F
    F --> G[HYBRID SEARCH<br/>Vector + Keyword N-gram + Direct Lookup]
    G --> H[BUILD PROMPT<br/>+ Disambiguation Rules<br/>+ Few-Shot Examples<br/>+ Citation Refs]
    H --> I[GEMINI LLM]
    I --> K[User Response]
```

---

## New & Modified Files

| Action | File | Purpose |
|--------|------|---------|
| **[NEW]** | `app/services/query_rewriter.py` | Contextual query rewriting pre-search |
| **[NEW]** | `tests/test_query_rewriter.py` | Query rewriter unit tests |
| **[MODIFY]** | `app/services/rag_pipeline.py` | Integrate rewriter + citation metadata into RAG flow |
| **[MODIFY]** | `app/services/vector_search.py` | Add `search_by_keyword()` + update `hybrid_search()` |
| **[MODIFY]** | `app/services/tax_system_prompt.py` | Disambiguation + persona + few-shot + citation instruction |
| **[MODIFY]** | `app/api/api_router.py` | Enriched sources in streaming path |
| **[MODIFY]** | `app/api/frontend_compat.py` | SSE sources event enrichment (id + url) |
| **[MODIFY]** | `app/models/rag_response.py` | Add `url` field to `SourceMetadata` |
| **[MODIFY]** | `app/models/api_models.py` | Add `id` + `url` fields to `SourceDetail` |
| **[MODIFY]** | `config.py` | New settings for keyword search, citations |
| **[MODIFY]** | `tests/test_system_prompt.py` | Updated assertions + 3 new tests |
| **[MODIFY]** | `tests/test_vector_search.py` | Keyword search tests |

---

## Risk & Mitigation

| Risk | Impact | Mitigation |
|------|--------|------------|
| Query rewriter adds latency | MEDIUM â€” UX degradation | Skip when no history; 3s timeout; `max_output_tokens=100` |
| Atlas Search index not created | MEDIUM â€” keyword search fails | Graceful fallback to vector-only; health check validates index |
| Disambiguation infinite loop | LOW â€” agent never answers | Limit to 1 clarifying question; if user already clarified, answer directly |
| Synonym map stale | LOW â€” abbreviations not found | Store in MongoDB `tax_synonyms` collection; admin refresh script |

---

> [!NOTE]
> **Task 1 (PII Scrubber) â€” DEFERRED.** Analysis concluded that for a general tax law Q&A agent,
> PII masking is not a functional requirement. Personal IDs do not aid the agent in answering
> questions, and data leakage risks are manageable with simpler alternatives. Deferred to a future sprint.

---

## Task 2: Active Disambiguation

> **Priority: ğŸŸ¢ Quick Win** â€” Prompt-level only, no architecture change

### Files
- **Modify:** `app/services/tax_system_prompt.py` (add section to BASE_SYSTEM_PROMPT)
- **Modify:** `tests/test_system_prompt.py` (new test)

### Prompt Addition

Add BETWEEN the numbered instructions (after item 5) and "áƒáƒ™áƒ áƒ«áƒáƒšáƒ£áƒšáƒ˜áƒ:" prohibition block in `BASE_SYSTEM_PROMPT`:

```
## áƒ“áƒáƒ›áƒáƒ–áƒ£áƒ¡áƒ¢áƒ”áƒ‘áƒ”áƒšáƒ˜ áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ (Disambiguation)

áƒ—áƒ£ áƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒšáƒ˜áƒ¡ áƒ¨áƒ”áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ áƒ‘áƒ£áƒœáƒ“áƒáƒ•áƒáƒœáƒ˜áƒ áƒ“áƒ áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒáƒ áƒ¡áƒ”áƒ‘áƒ˜áƒ—áƒáƒ“ áƒ’áƒáƒœáƒ¡áƒ®áƒ•áƒáƒ•áƒ“áƒ”áƒ‘áƒ 
áƒ˜áƒ£áƒ áƒ˜áƒ“áƒ˜áƒ£áƒšáƒ˜ áƒ¡áƒ¢áƒáƒ¢áƒ£áƒ¡áƒ˜áƒ¡ áƒ›áƒ˜áƒ®áƒ”áƒ“áƒ•áƒ˜áƒ— (áƒ¤áƒ˜áƒ–áƒ˜áƒ™áƒ£áƒ áƒ˜/áƒ˜áƒ£áƒ áƒ˜áƒ“áƒ˜áƒ£áƒšáƒ˜ áƒáƒ˜áƒ áƒ˜, áƒ›áƒ˜áƒ™áƒ áƒ/áƒ›áƒªáƒ˜áƒ áƒ”/áƒ¡áƒáƒ¨áƒ£áƒáƒšáƒ 
áƒ‘áƒ˜áƒ–áƒœáƒ”áƒ¡áƒ˜, áƒ“áƒ¦áƒ’-áƒ¡ áƒ’áƒáƒ“áƒáƒ›áƒ®áƒ“áƒ”áƒšáƒ˜/áƒáƒ áƒáƒ’áƒáƒ“áƒáƒ›áƒ®áƒ“áƒ”áƒšáƒ˜), áƒ›áƒáƒ¨áƒ˜áƒœ:

1. áƒ“áƒáƒ£áƒ¡áƒ•áƒ˜ áƒ›áƒáƒ¥áƒ¡áƒ˜áƒ›áƒ£áƒ› 1 áƒ›áƒáƒ™áƒšáƒ”, áƒ™áƒáƒœáƒ™áƒ áƒ”áƒ¢áƒ£áƒšáƒ˜ áƒ“áƒáƒ›áƒáƒ–áƒ£áƒ¡áƒ¢áƒ”áƒ‘áƒ”áƒšáƒ˜ áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ
2. áƒáƒ®áƒ¡áƒ”áƒœáƒ˜, áƒ áƒáƒ¢áƒáƒ› áƒáƒ áƒ˜áƒ¡ áƒ”áƒ¡ áƒ˜áƒœáƒ¤áƒáƒ áƒ›áƒáƒªáƒ˜áƒ áƒ›áƒœáƒ˜áƒ¨áƒ•áƒœáƒ”áƒšáƒáƒ•áƒáƒœáƒ˜
3. áƒ—áƒ£ áƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒ”áƒšáƒ›áƒ áƒ£áƒ™áƒ•áƒ” áƒ“áƒáƒáƒ–áƒ£áƒ¡áƒ¢áƒ áƒ¬áƒ˜áƒœáƒ áƒ¨áƒ”áƒ¢áƒ§áƒáƒ‘áƒ˜áƒœáƒ”áƒ‘áƒáƒ¨áƒ˜ â€” áƒ£áƒáƒáƒ¡áƒ£áƒ®áƒ” áƒáƒ˜áƒ áƒ“áƒáƒáƒ˜áƒ 

áƒáƒ áƒáƒ¡áƒ“áƒ áƒáƒ¡ áƒ“áƒáƒ£áƒ¡áƒ•áƒ 2+ áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ áƒ”áƒ áƒ—áƒ“áƒ áƒáƒ£áƒšáƒáƒ“. áƒáƒ áƒáƒ¡áƒ“áƒ áƒáƒ¡ áƒ˜áƒ™áƒ˜áƒ—áƒ®áƒ áƒ˜áƒ¡, áƒ áƒáƒª áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜áƒ“áƒáƒœ 
áƒªáƒ®áƒáƒ“áƒ˜áƒ.
```

### TDD Steps

**Step 1:** Add test `test_disambiguation_section_present`  
**Step 2:** Run â†’ FAIL  
**Step 3:** Add section to BASE_SYSTEM_PROMPT  
**Step 4:** Run â†’ PASS  

---

## Task 3: System Prompt Upgrade (Empathic Persona + Few-Shot)

> **Priority: ğŸŸ¡ Medium** â€” From existing implementation_plan.md

### Files
- **Modify:** `app/services/tax_system_prompt.py` (BASE_SYSTEM_PROMPT + build_system_prompt)
- **Modify:** `tests/test_system_prompt.py` (update assertions + 3 new tests)

### Changes (from existing plan â€” unchanged)
1. Rewrite BASE_SYSTEM_PROMPT with empathic persona + 4-step response format
2. Add Few-Shot examples (GOOD vs BAD answer for áƒ“áƒ¦áƒ’ question)
3. Update empty-context fallback
4. Update definitions section header

### TDD Steps (9 total tests)
See existing `implementation_plan.md` â€” Steps unchanged.

---

## Task 4: Contextual Query Rewriter

> **Priority: ğŸŸ¡ Medium** â€” Improves multi-turn retrieval quality

### Files
- **Create:** `app/services/query_rewriter.py`
- **Create:** `tests/test_query_rewriter.py`
- **Modify:** `app/services/rag_pipeline.py` (call rewriter before search)
- **Modify:** `config.py` (add `query_rewrite_model`, `query_rewrite_timeout`)

### Architecture

```python
# query_rewriter.py â€” Interface

REWRITE_PROMPT = """
áƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒšáƒ˜áƒ¡ áƒáƒ®áƒáƒšáƒ˜ áƒ¨áƒ”áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ áƒ¨áƒ”áƒ˜áƒ«áƒšáƒ”áƒ‘áƒ áƒ”áƒ§áƒ áƒ“áƒœáƒáƒ‘áƒáƒ“áƒ”áƒ¡ áƒ¬áƒ˜áƒœáƒ áƒ“áƒ˜áƒáƒšáƒáƒ’áƒ¡.
áƒ’áƒáƒ“áƒáƒáƒ™áƒ”áƒ—áƒ” áƒ”áƒ¡ áƒ¨áƒ”áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ áƒ“áƒáƒ›áƒáƒ£áƒ™áƒ˜áƒ“áƒ”áƒ‘áƒ”áƒš, áƒ¡áƒ áƒ£áƒš áƒ™áƒ˜áƒ—áƒ®áƒ•áƒáƒ“ áƒ áƒáƒ›áƒ”áƒšáƒ˜áƒª 
áƒ¡áƒáƒ«áƒ˜áƒ”áƒ‘áƒ áƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒ›áƒáƒ¡ áƒ’áƒáƒ£áƒ’áƒ”áƒ‘áƒ¡ áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜áƒ¡ áƒ’áƒáƒ áƒ”áƒ¨áƒ”.

áƒ“áƒ˜áƒáƒšáƒáƒ’áƒ˜áƒ¡ áƒ˜áƒ¡áƒ¢áƒáƒ áƒ˜áƒ:
{history}

áƒáƒ®áƒáƒšáƒ˜ áƒ¨áƒ”áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ: {query}

áƒ“áƒáƒ›áƒáƒ£áƒ™áƒ˜áƒ“áƒ”áƒ‘áƒ”áƒšáƒ˜ áƒ¨áƒ”áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ:
"""

async def rewrite_query(
    query: str,
    history: Optional[List[dict]] = None,
) -> str:
    """Rewrite follow-up query as standalone using conversation context.
    
    Returns original query if:
    - No history provided
    - History is empty  
    - Rewriter times out (3s max)
    - Any error occurs (fail-safe: never block the pipeline)
    """
```

### Integration in rag_pipeline.py

```python
# In answer_question(), BEFORE hybrid_search():

# Step 0.5: Rewrite query if history exists
search_query = query  # default: use original
if history and len(history) > 0:
    search_query = await rewrite_query(query, history)

# Step 2: Search (now uses rewritten query)
results = hybrid_search(search_query)
```

### TDD Steps

**Step 1: Write failing tests**
```python
def test_no_history_returns_original():
    result = await rewrite_query("áƒ áƒ áƒáƒ áƒ˜áƒ¡ áƒ“áƒ¦áƒ’?", history=None)
    assert result == "áƒ áƒ áƒáƒ áƒ˜áƒ¡ áƒ“áƒ¦áƒ’?"

def test_empty_history_returns_original():
    result = await rewrite_query("áƒ“áƒ áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?", history=[])
    assert result == "áƒ“áƒ áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?"

@patch("app.services.query_rewriter.get_genai_client")
def test_rewrites_with_history(mock_client):
    mock_client.return_value.models.generate_content.return_value.text = \
        "áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ áƒ“áƒ¦áƒ’-áƒ¡ áƒ’áƒáƒœáƒáƒ™áƒ•áƒ”áƒ—áƒ˜ áƒ¡áƒáƒ¥áƒáƒ áƒ—áƒ•áƒ”áƒšáƒáƒ¨áƒ˜?"
    history = [
        {"role": "user", "content": "áƒ áƒ áƒáƒ áƒ˜áƒ¡ áƒ“áƒ¦áƒ’?"},
        {"role": "assistant", "content": "áƒ“áƒ¦áƒ’ áƒáƒ áƒ˜áƒ¡ áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒ¦áƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ’áƒáƒ“áƒáƒ¡áƒáƒ®áƒáƒ“áƒ˜."},
    ]
    result = await rewrite_query("áƒ“áƒ áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?", history=history)
    assert "áƒ“áƒ¦áƒ’" in result
    assert len(result) > len("áƒ“áƒ áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?")

def test_timeout_returns_original():
    # Mock client to raise TimeoutError
    result = await rewrite_query("áƒ“áƒ áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?", history=[...])
    assert result == "áƒ“áƒ áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?"  # Graceful fallback
```

**Step 2:** Run â†’ FAIL  
**Step 3:** Implement `query_rewriter.py`  
**Step 4:** Run â†’ PASS  
**Step 5:** Integrate into `rag_pipeline.py`  
**Step 6:** Run full pipeline test

---

## Task 5: Enhanced Keyword Search (Edge N-grams + Synonym Map)

> **Priority: ğŸŸ¡ Medium** â€” Completes the true hybrid search

### Files
- **Modify:** `app/services/vector_search.py` (add `search_by_keyword()`, update `hybrid_search()`)
- **Modify:** `config.py` (add `keyword_search_enabled` flag)
- **Modify:** `tests/test_vector_search.py` (keyword search tests)
- **Create:** Atlas Search index definition (documented, not code)

### Atlas Search Index (Manual Setup Required)

> [!IMPORTANT]
> This index must be created via Atlas UI or `mongosh`. It CANNOT be created via pymongo.

```json
{
  "name": "tax_articles_keyword",
  "analyzer": "georgianNgram",
  "searchAnalyzer": "georgianNgram",
  "mappings": {
    "dynamic": false,
    "fields": {
      "body_ka": {
        "type": "string",
        "analyzer": "georgianNgram"
      },
      "title_ka": {
        "type": "string",
        "analyzer": "georgianNgram"
      }
    }
  },
  "analyzers": [
    {
      "name": "georgianNgram",
      "tokenizer": { "type": "standard" },
      "tokenFilters": [
        { "type": "lowercase" },
        { "type": "edgeGram", "minGrams": 3, "maxGrams": 15 }
      ]
    }
  ],
  "synonyms": [
    {
      "name": "taxSynonyms",
      "analyzer": "georgianNgram",
      "source": { "collection": "tax_synonyms" }
    }
  ]
}
```

### Synonym Map Collection (`tax_synonyms`)

```json
[
  {"mappingType": "equivalent", "synonyms": ["áƒ¡áƒ¡áƒ™", "áƒ¡áƒáƒ¥áƒáƒ áƒ—áƒ•áƒ”áƒšáƒáƒ¡ áƒ¡áƒáƒ’áƒáƒ“áƒáƒ¡áƒáƒ®áƒáƒ“áƒ áƒ™áƒáƒ“áƒ”áƒ¥áƒ¡áƒ˜", "áƒ¡áƒáƒ’áƒáƒ“áƒáƒ¡áƒáƒ®áƒáƒ“áƒ áƒ™áƒáƒ“áƒ”áƒ¥áƒ¡áƒ˜"]},
  {"mappingType": "equivalent", "synonyms": ["áƒ“áƒ¦áƒ’", "áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒ¦áƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ’áƒáƒ“áƒáƒ¡áƒáƒ®áƒáƒ“áƒ˜"]},
  {"mappingType": "equivalent", "synonyms": ["áƒ¡áƒáƒ¨áƒ”áƒ›áƒáƒ¡áƒáƒ•áƒšáƒ", "áƒ¡áƒáƒ¨áƒ”áƒ›áƒáƒ¡áƒáƒ•áƒšáƒ áƒ’áƒáƒ“áƒáƒ¡áƒáƒ®áƒáƒ“áƒ˜", "income tax"]},
  {"mappingType": "equivalent", "synonyms": ["áƒ›áƒáƒ’áƒ”áƒ‘áƒ˜áƒ¡ áƒ’áƒáƒ“áƒáƒ¡áƒáƒ®áƒáƒ“áƒ˜", "profit tax", "CIT"]},
  {"mappingType": "equivalent", "synonyms": ["áƒ˜/áƒ›", "áƒ˜áƒœáƒ“áƒ˜áƒ•áƒ˜áƒ“áƒ£áƒáƒšáƒ£áƒ áƒ˜ áƒ›áƒ”áƒ¬áƒáƒ áƒ›áƒ”", "individual entrepreneur"]},
  {"mappingType": "equivalent", "synonyms": ["áƒ¨áƒáƒ¡", "áƒ¨áƒ”áƒ–áƒ¦áƒ£áƒ“áƒ£áƒšáƒ˜ áƒáƒáƒ¡áƒ£áƒ®áƒ˜áƒ¡áƒ›áƒ’áƒ”áƒ‘áƒšáƒáƒ‘áƒ˜áƒ¡ áƒ¡áƒáƒ–áƒáƒ’áƒáƒ“áƒáƒ”áƒ‘áƒ", "LLC"]},
  {"mappingType": "equivalent", "synonyms": ["áƒ¡áƒ¡", "áƒ¡áƒáƒáƒ¥áƒªáƒ˜áƒ áƒ¡áƒáƒ–áƒáƒ’áƒáƒ“áƒáƒ”áƒ‘áƒ", "JSC"]}
]
```

### New Function in vector_search.py

```python
def search_by_keyword(query: str, limit: int = 5) -> List[dict]:
    """Atlas Search keyword lookup using Edge N-gram analyzer.
    
    Graceful fallback: returns empty list if Atlas Search index 
    doesn't exist or $search fails.
    """
    try:
        pipeline = [
            {"$search": {
                "index": "tax_articles_keyword",
                "text": {
                    "query": query,
                    "path": ["body_ka", "title_ka"],
                },
                "count": {"type": "total"}
            }},
            {"$limit": limit},
            {"$addFields": {
                "search_score": {"$meta": "searchScore"},
                "search_type": "keyword"
            }},
        ]
        return list(collection.aggregate(pipeline))
    except Exception as e:
        logger.warning("keyword_search_failed", error=str(e))
        return []  # Graceful fallback
```

### Updated hybrid_search() Flow

```python
def hybrid_search(query: str) -> List[dict]:
    article_num = detect_article_number(query)
    
    if article_num:
        direct = find_by_number(article_num)
        semantic = search_by_semantic(query, limit=settings.search_limit)
        keyword = search_by_keyword(query, limit=3)  # NEW
    else:
        semantic = search_by_semantic(query)
        keyword = search_by_keyword(query, limit=settings.search_limit)  # NEW
        direct = []
    
    merged = merge_and_rank(direct + semantic + keyword)  # 3-way merge
    enriched = enrich_with_cross_refs(merged)
    return rerank_with_exceptions(enriched)
```

### TDD Steps

**Step 1:** Add tests for `search_by_keyword` (mock MongoDB aggregate)  
**Step 2:** Run â†’ FAIL  
**Step 3:** Implement `search_by_keyword()` in `vector_search.py`  
**Step 4:** Run â†’ PASS  
**Step 5:** Update `hybrid_search()` for 3-way merge  
**Step 6:** Update `merge_and_rank()` to handle `search_type` field  

---

## Task 7: Citation Sidebar Backend (Grounded UI)

> **Priority: ğŸŸ¡ Medium** â€” Enables interactive source verification in frontend
>
> **Dependency:** Must execute AFTER Task 3 (both modify `build_system_prompt()`)

### Architecture Decision

**Selected: Lazy-load via existing `/api/articles/{N}` endpoint**
- SSE `sources` event sends: `{ id, article_number, title, url, score }`
- Frontend fetches full article text on sidebar open via `GET /api/articles/{article_number}`
- `ArticleResponse` already returns `body_ka` â€” zero new endpoints needed

Rejected alternatives:
- Inline full text in SSE â†’ bloats payload by 5-50KB per response
- Hybrid text_preview â†’ over-engineering for v1

### Files
- **Modify:** `app/models/rag_response.py` (line 14: add `url` to `SourceMetadata`)
- **Modify:** `app/models/api_models.py` (line 53: add `id` + `url` to `SourceDetail`)
- **Modify:** `app/services/rag_pipeline.py` (line 67: `_extract_source_metadata` + line 140: pass sources to prompt)
- **Modify:** `app/services/tax_system_prompt.py` (line 45: add `source_refs` param + citation instruction)
- **Modify:** `app/api/frontend_compat.py` (line ~175: enrich SSE sources with `id` + `url`)
- **Modify:** `app/api/api_router.py` (line ~195: enrich SSE sources with `id` + `url`)
- **Modify:** `config.py` (add `citation_enabled` flag + `MATSNE_BASE_URL`)

### Data Contract Changes

**`SourceMetadata` (rag_response.py) â€” add `url`:**
```python
class SourceMetadata(BaseModel):
    article_number: Optional[str] = None
    chapter: Optional[str] = None
    title: Optional[str] = None
    score: float = 0.0
    url: Optional[str] = None  # NEW: Matsne deep-link
```

**`SourceDetail` (api_models.py) â€” add `id` + `url`:**
```python
class SourceDetail(BaseModel):
    id: int = 0                     # NEW: Sequential citation ID (1, 2, 3...)
    article_number: Optional[str] = None
    chapter: Optional[str] = None
    title: Optional[str] = None
    score: float = 0.0
    url: Optional[str] = None       # NEW: Matsne deep-link
```

### Source URL Construction

```python
# config.py
MATSNE_BASE_URL: str = "https://matsne.gov.ge/ka/document/view/1043717/most-current-version"

# _extract_source_metadata() in rag_pipeline.py
def _extract_source_metadata(results: List[dict]) -> List[SourceMetadata]:
    metadata = []
    for i, r in enumerate(results):
        art_num = r.get("article_number")
        url = f"{settings.matsne_base_url}#Article_{art_num}" if art_num else None
        metadata.append(SourceMetadata(
            article_number=str(art_num) if art_num else None,
            chapter=r.get("chapter"),
            title=r.get("title"),
            score=r.get("score", 0.0),
            url=url,
        ))
    return metadata
```

### Citation Prompt Instruction

**Add to `build_system_prompt()` signature:**
```python
def build_system_prompt(
    *,
    context_chunks: List[str],
    definitions: Optional[List[dict]] = None,
    source_refs: Optional[List[dict]] = None,  # NEW
    is_red_zone: bool = False,
    temporal_year: Optional[int] = None,
) -> str:
```

**Add citation section to assembled prompt (after context):**
```python
# â”€â”€ Inject citation instruction
if source_refs:
    citation_lines = []
    for ref in source_refs:
        line = f"[{ref['id']}] áƒ›áƒ£áƒ®áƒšáƒ˜ {ref['article_number']}: {ref['title']}"
        citation_lines.append(line)
    parts.append(
        "\n\n## áƒªáƒ˜áƒ¢áƒáƒ¢áƒ (Citation)\n"
        "áƒáƒáƒ¡áƒ£áƒ®áƒ¨áƒ˜ áƒ’áƒáƒ›áƒáƒ˜áƒ§áƒ”áƒœáƒ” [1], [2] áƒ¤áƒáƒ áƒ›áƒáƒ¢áƒ˜áƒ¡ áƒªáƒ˜áƒ¢áƒáƒ¢áƒ”áƒ‘áƒ˜ áƒ¬áƒ§áƒáƒ áƒáƒ”áƒ‘áƒ˜áƒ¡ áƒ›áƒ˜áƒ¡áƒáƒ—áƒ˜áƒ—áƒ”áƒ‘áƒšáƒáƒ“.\n"
        "áƒ®áƒ”áƒšáƒ›áƒ˜áƒ¡áƒáƒ¬áƒ•áƒ“áƒáƒ›áƒ˜ áƒ¬áƒ§áƒáƒ áƒáƒ”áƒ‘áƒ˜:\n" + "\n".join(citation_lines)
    )
```

**Update `answer_question()` to pass sources:**
```python
# In rag_pipeline.py, after search_results are extracted:
source_metadata = _extract_source_metadata(search_results)
source_refs = [
    {"id": i + 1, "article_number": s.article_number, "title": s.title}
    for i, s in enumerate(source_metadata)
]

system_prompt = build_system_prompt(
    context_chunks=context_chunks,
    definitions=definitions,
    source_refs=source_refs,  # NEW
    is_red_zone=is_red_zone,
    temporal_year=temporal_year,
)
```

### SSE Sources Event Enrichment

**Both `api_router.py` and `frontend_compat.py`:**
```python
# Replace current sources_data construction:
sources_data = [
    {
        "id": i + 1,                    # NEW: sequential citation ID
        "article_number": s.article_number,
        "chapter": s.chapter,
        "title": s.title,
        "score": s.score,
        "url": s.url,                   # NEW: Matsne deep-link
    }
    for i, s in enumerate(rag_response.source_metadata)
]
yield _sse("sources", sources_data)

# REMOVE inline text source append ("ğŸ“š áƒ¬áƒ§áƒáƒ áƒáƒ”áƒ‘áƒ˜:" block)
# Frontend will render citation sidebar instead
```

> [!IMPORTANT]
> The inline text source append ("ğŸ“š **áƒ¬áƒ§áƒáƒ áƒáƒ”áƒ‘áƒ˜:**") in both SSE generators is REMOVED.
> Frontend renders citations in the sidebar instead of as trailing text.

### TDD Steps

**Step 1: Write failing tests**
```python
# tests/test_citation_backend.py
def test_source_metadata_has_url():
    sm = SourceMetadata(article_number="165", title="áƒ“áƒ¦áƒ’", score=0.9)
    assert hasattr(sm, "url")

def test_source_detail_has_id_and_url():
    sd = SourceDetail(id=1, article_number="165", url="https://matsne.gov.ge/...")
    assert sd.id == 1
    assert sd.url.startswith("https://")

def test_extract_source_metadata_constructs_url():
    results = [{"article_number": 165, "chapter": "1", "title": "áƒ“áƒ¦áƒ’", "score": 0.9}]
    metadata = _extract_source_metadata(results)
    assert metadata[0].url is not None
    assert "Article_165" in metadata[0].url

def test_build_system_prompt_with_source_refs():
    refs = [{"id": 1, "article_number": "165", "title": "áƒ“áƒ¦áƒ’"}]
    prompt = build_system_prompt(context_chunks=["context"], source_refs=refs)
    assert "[1]" in prompt
    assert "áƒ›áƒ£áƒ®áƒšáƒ˜ 165" in prompt

def test_build_system_prompt_without_source_refs():
    """Without source_refs, no citation section is injected."""
    prompt = build_system_prompt(context_chunks=["context"])
    assert "áƒªáƒ˜áƒ¢áƒáƒ¢áƒ" not in prompt  # Citation section absent

def test_citation_disabled_skips_refs():
    """When citation_enabled=False, source_refs not passed to prompt."""
    # Mock settings.citation_enabled = False
    # Assert build_system_prompt called WITHOUT source_refs

def test_sse_sources_event_has_id_and_url():
    """SSE sources event includes id and url fields."""
    # Mock answer_question response with source_metadata
    # Parse SSE events from streaming endpoint
    # Assert each source dict has 'id' (int) and 'url' (str|None)

def test_sse_no_inline_sources_text():
    """SSE stream does NOT append 'ğŸ“š áƒ¬áƒ§áƒáƒ áƒáƒ”áƒ‘áƒ˜:' text block."""
    # Assert no SSE text event contains "ğŸ“š áƒ¬áƒ§áƒáƒ áƒáƒ”áƒ‘áƒ˜"
```

**Step 2:** Run tests â†’ verify FAIL
**Step 3:** Implement model changes (SourceMetadata + SourceDetail)
**Step 4:** Run model tests â†’ verify PASS
**Step 5:** Implement `_extract_source_metadata` URL construction
**Step 6:** Implement `build_system_prompt` citation injection
**Step 7:** Update SSE generators (both endpoints)
**Step 8:** Run all tests â†’ verify PASS

---

## Task 6: Integration & E2E Verification

> **Priority: ğŸŸ¢ Final Gate**

### Verification Checklist

```bash
# 1. Run ALL unit tests
cd /Users/maqashable/Desktop/scoop-sagadasaxado/tax_agent
.venv/bin/python -m pytest tests/ -v --tb=short

# 2. Run query rewriter tests
.venv/bin/python -m pytest tests/test_query_rewriter.py -v

# 3. Run system prompt tests (9 total)
.venv/bin/python -m pytest tests/test_system_prompt.py -v

# 4. Run vector search tests
.venv/bin/python -m pytest tests/test_vector_search.py -v

# 5. Run citation backend tests
.venv/bin/python -m pytest tests/test_citation_backend.py -v
```

### Manual E2E Test

```bash

# Test citation markers in response (NEW)
curl -s http://localhost:8000/api/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "áƒ áƒ áƒáƒ áƒ˜áƒ¡ áƒ“áƒ¦áƒ’-áƒ¡ áƒ’áƒáƒœáƒáƒ™áƒ•áƒ”áƒ—áƒ˜?"}' | jq '.sources[0]'

# Verify: sources array has id, article_number, title, url fields
# Verify: answer contains [1] or [2] citation markers
# Verify: url starts with https://matsne.gov.ge/
```

---

## ADDENDUM A: Gap Remediation (18 Gaps Fixed)

> **Added:** 2026-02-17 | **Source:** Claude-Building v3.0 Simulation
>
> This addendum resolves all 18 gaps identified during pre-execution simulation.
> The original plan above remains unchanged â€” this addendum **supplements** it.

---

### A1: Task Sizing Classification (M1)

| Task | Building Mode | Estimated Time | Files Touched |
|------|--------------|----------------|---------------|
| 2. Disambiguation | **S** (Small) | 15-20 min | 2 files |
| 3. Prompt Upgrade | **M** (Medium) | 30-45 min | 2 files |
| 4. Query Rewriter | **M** (Medium) | 30-45 min | 4 files |
| 5. Keyword Search | **L** (Large) | 60-90 min | 3 files |
| 7. Citation Backend | **M** (Medium) | 30-45 min | 7 files |
| 6. Integration E2E | **M** (Medium) | 30 min | 0 files (test-only) |

**Sprint Total:** ~3.5-4.5 hours of focused execution.

---

### A2: Task Execution Order & Merge Strategy (H4)

> [!IMPORTANT]
> `rag_pipeline.py` is modified by Task 4. `tax_system_prompt.py` is modified by Tasks 3 AND 7. Strict execution order required.

**Mandatory Order:**
```
Task 2 (S, standalone) â†’ Task 3 (M, prompt-only) â†’
Task 4 (M, rewriter â€” modifies rag_pipeline) â†’
Task 5 (L, keyword search â€” vector_search.py only) â†’
Task 7 (M, citation backend â€” AFTER Task 3, extends prompt + models) â†’
Task 6 (M, integration tests)
```

> [!IMPORTANT]
> Task 7 must execute AFTER Task 3 because both modify `build_system_prompt()`.
> Task 7 extends the signature with `source_refs` â€” cannot conflict with Task 3's persona/few-shot additions.

**Merge Strategy for `rag_pipeline.py`:**
```python
async def answer_question(query, *, history=None):
    # â”€â”€â”€ REWRITE LAYER (Task 4) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    search_query = query
    if history and len(history) > 0:
        search_query = await rewrite_query(query, history)

    # â”€â”€â”€ EXISTING PIPELINE (unchanged) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    classifiers = ...
    results = hybrid_search(search_query)
    prompt = build_system_prompt(...)
    response = await generate(...)

    return response
```

**Commit after each task â€” one commit per task.**

---

### A3: Score Normalization Strategy (C4)

> [!CAUTION]
> Atlas Search `searchScore` is unbounded (0-10+). Vector `score` is 0-1. Direct merge breaks ranking.

**Strategy: Reciprocal Rank Fusion (RRF)**

```python
def merge_and_rank(results: List[dict], k: int = 60) -> List[dict]:
    """Merge multi-source results using RRF â€” score-scale agnostic."""
    rrf_scores = {}

    # Group by source type
    for source_type in ["direct", "semantic", "keyword"]:
        source_results = [r for r in results if r.get("search_type") == source_type]
        # Sort by native score (descending) within source
        source_results.sort(key=lambda r: r.get("score", r.get("search_score", 0)), reverse=True)
        for rank, result in enumerate(source_results):
            art_num = result["article_number"]
            rrf_scores[art_num] = rrf_scores.get(art_num, 0) + 1.0 / (k + rank + 1)

    # Assign RRF score to results, deduplicate
    seen = set()
    merged = []
    for result in results:
        art_num = result["article_number"]
        if art_num not in seen:
            seen.add(art_num)
            result["rrf_score"] = rrf_scores.get(art_num, 0)
            merged.append(result)

    merged.sort(key=lambda r: r["rrf_score"], reverse=True)
    return merged[:10]  # Top-10
```

**Why RRF:** No need to normalize score scales. Well-proven in hybrid search. Parameter `k=60` is standard (Cormack et al.).

---

### A4: Rollback Plan (C2)

| If This Fails... | Revert These Files | Restore State | Alternative |
|---|---|---|---|
| Task 2: Disambiguation confuses LLM | `tax_system_prompt.py` | Remove disambiguation section from `BASE_SYSTEM_PROMPT` | Reduce to single-line instruction |
| Task 3: Prompt upgrade degrades quality | `tax_system_prompt.py` | `git stash` + restore previous BASE_SYSTEM_PROMPT | A/B test old vs new |
| Task 4: Query rewriter adds latency/noise | `query_rewriter.py`, `rag_pipeline.py` | Delete rewriter, remove call from pipeline | Already has `if history` guard â€” just skip |
| Task 5: Keyword search returns noise | `vector_search.py` | Set `keyword_search_enabled=false` | Vector-only fallback (existing behavior) |
| Task 7: Citation backend breaks prompt | `tax_system_prompt.py`, models | `git revert HEAD~1` | Set `citation_enabled=false` flag |
| Integration breaks | Multiple files | `git revert` to last green commit | Re-run tasks individually |

**Feature Flags for Safe Rollback (add to `config.py`):**
```python
# config.py â€” new settings
keyword_search_enabled: bool = Field(default=True, description="Enable/disable keyword search")
query_rewrite_enabled: bool = Field(default=True, description="Enable/disable query rewriting")
synonym_collection_name: str = Field(default="tax_synonyms", description="Synonym map collection")
citation_enabled: bool = Field(default=True, description="Enable/disable citation injection")
```

---

### A5: Acceptance Criteria Per Task (H1)

**Task 2 â€” Disambiguation: DONE WHEN:**
- Disambiguation section present in built prompt
- Max 1 question rule text present
- "Already clarified" rule text present
- All 3 unit tests pass

**Task 3 â€” Prompt Upgrade: DONE WHEN:**
- Empathic persona header present in prompt
- 4-step response format present
- Few-shot example (GOOD vs BAD) present
- All 9 unit tests pass (6 existing + 3 new)

**Task 4 â€” Query Rewriter: DONE WHEN:**
- All 9 unit tests pass (4 existing + 5 new)
- No-history returns original (< 1ms)
- Timeout returns original (graceful)
- API error returns original (graceful)
- Georgian characters preserved in rewrite

**Task 5 â€” Keyword Search: DONE WHEN:**
- All 7 keyword-specific unit tests pass
- `search_by_keyword` returns results with `search_score` field
- Missing Atlas index returns `[]` (no crash)
- `hybrid_search` performs 3-way merge via RRF
- Feature flag `keyword_search_enabled=false` skips keyword entirely

**Task 7 â€” Citation Backend: DONE WHEN:**
- `SourceMetadata` has `url` field, `SourceDetail` has `id` + `url` fields
- `_extract_source_metadata()` constructs Matsne URL per source
- `build_system_prompt()` injects citation instruction when `source_refs` provided
- `build_system_prompt()` omits citation section when `source_refs` is `None`
- SSE sources event includes `id` (int) and `url` (str) per source
- No inline "ğŸ“š áƒ¬áƒ§áƒáƒ áƒáƒ”áƒ‘áƒ˜:" text block in SSE stream
- All 8 citation-specific unit tests pass
- `citation_enabled` feature flag toggles citation injection

**Task 6 â€” Integration: DONE WHEN:**
- All existing tests still pass (zero regressions)
- Full pipeline integration test passes (Rewriteâ†’Searchâ†’Disambigâ†’Citation)
- Manual curl test: sources array has `id`, `url` fields; answer has `[N]` markers

---

### A6: Complete Test Specifications

> Task 1 (PII Scrubber) tests removed â€” feature deferred.

#### Task 2 â€” Disambiguation: 3 Tests Total

**1 existing:** `test_disambiguation_section_present`

**2 NEW:**
```python
def test_disambiguation_max_one_question_rule():
    """The 'max 1 question' rule is in the built prompt."""
    prompt = build_system_prompt(context_chunks=["context"])
    assert "áƒ›áƒáƒ¥áƒ¡áƒ˜áƒ›áƒ£áƒ› 1" in prompt

def test_disambiguation_already_clarified_rule():
    """The 'already clarified â†’ answer directly' rule is in the prompt."""
    prompt = build_system_prompt(context_chunks=["context"])
    assert "áƒ£áƒ™áƒ•áƒ” áƒ“áƒáƒáƒ–áƒ£áƒ¡áƒ¢áƒ" in prompt
```

#### Task 3 â€” Prompt Upgrade: 9 Tests Total (Inlined â€” H5 fixed)

**6 existing:** `test_contains_base_prompt`, `test_context_injected`, `test_red_zone_disclaimer_added`, `test_temporal_warning_includes_year`, `test_definitions_injected`, `test_empty_context_shows_fallback`

**3 NEW:**
```python
def test_empathic_persona_header():
    """Upgraded prompt contains empathic consultant persona."""
    prompt = build_system_prompt(context_chunks=["context"])
    assert "áƒ™áƒáƒœáƒ¡áƒ£áƒšáƒ¢áƒáƒœáƒ¢áƒ˜" in prompt or "áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ¢áƒ˜" in prompt

def test_response_format_four_steps():
    """Prompt contains the 4-step structured response format."""
    prompt = build_system_prompt(context_chunks=["context"])
    # Check for numbered response steps or format markers
    assert "1." in prompt and "2." in prompt

def test_few_shot_example_present():
    """Prompt contains at least one few-shot example with GOOD/BAD pattern."""
    prompt = build_system_prompt(context_chunks=["context"])
    assert "áƒ›áƒáƒ’áƒáƒšáƒ˜áƒ—áƒ˜" in prompt or "áƒœáƒ˜áƒ›áƒ£áƒ¨áƒ˜" in prompt  # Example marker
```

#### Task 4 â€” Query Rewriter: 9 Tests Total

**4 existing:** `test_no_history_returns_original`, `test_empty_history_returns_original`, `test_rewrites_with_history`, `test_timeout_returns_original`

**Fix for `test_timeout_returns_original` (H3 â€” placeholder fixed):**
```python
@patch("app.services.query_rewriter.get_genai_client")
async def test_timeout_returns_original(mock_client):
    mock_client.return_value.models.generate_content.side_effect = TimeoutError()
    history = [
        {"role": "user", "content": "áƒ áƒ áƒáƒ áƒ˜áƒ¡ áƒ“áƒ¦áƒ’?"},
        {"role": "assistant", "content": "áƒ“áƒ¦áƒ’ áƒáƒ áƒ˜áƒ¡ áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒ¦áƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ’áƒáƒ“áƒáƒ¡áƒáƒ®áƒáƒ“áƒ˜."},
    ]
    result = await rewrite_query("áƒ“áƒ áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?", history=history)
    assert result == "áƒ“áƒ áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?"
```

**5 NEW:**
```python
@patch("app.services.query_rewriter.get_genai_client")
async def test_api_error_returns_original(mock_client):
    """Non-timeout errors also gracefully return original."""
    mock_client.return_value.models.generate_content.side_effect = Exception("API down")
    result = await rewrite_query("áƒ“áƒ áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?", history=[{"role": "user", "content": "test"}])
    assert result == "áƒ“áƒ áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?"

async def test_history_formatting_in_prompt():
    """Verify history is formatted as 'role: content' lines in prompt."""
    # This tests the internal prompt template construction

@patch("app.services.query_rewriter.get_genai_client")
async def test_rewrite_strips_whitespace(mock_client):
    """LLM might return padded text â€” strip it."""
    mock_client.return_value.models.generate_content.return_value.text = \
        "  áƒ“áƒ¦áƒ’-áƒ¡ áƒ’áƒáƒœáƒáƒ™áƒ•áƒ”áƒ—áƒ˜ áƒ¡áƒáƒ¥áƒáƒ áƒ—áƒ•áƒ”áƒšáƒáƒ¨áƒ˜  \n"
    result = await rewrite_query("áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?", history=[{"role": "user", "content": "test"}])
    assert not result.startswith(" ")
    assert not result.endswith("\n")

@patch("app.services.query_rewriter.get_genai_client")
async def test_preserves_georgian_characters(mock_client):
    """UTF-8 Georgian text survives round-trip through rewriter."""
    georgian_text = "áƒ¡áƒáƒ¥áƒáƒ áƒ—áƒ•áƒ”áƒšáƒáƒ¨áƒ˜ áƒ“áƒ¦áƒ’-áƒ¡ áƒ’áƒáƒœáƒáƒ™áƒ•áƒ”áƒ—áƒ˜ áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?"
    mock_client.return_value.models.generate_content.return_value.text = georgian_text
    result = await rewrite_query("áƒ áƒáƒ›áƒ“áƒ”áƒœáƒ˜áƒ?", history=[{"role": "user", "content": "test"}])
    assert result == georgian_text

async def test_rewriter_called_in_pipeline():
    """Integration: rag_pipeline calls rewrite_query when history present."""
    # Mock rewrite_query, call answer_question with history
    # Assert rewrite_query was called with expected args
```

#### Task 5 â€” Keyword Search: 7 Tests (C3 â€” all NEW)

```python
@patch("app.services.vector_search.collection")
def test_keyword_search_returns_results(mock_coll):
    """search_by_keyword returns results with search_score field."""
    mock_coll.aggregate.return_value = [
        {"article_number": 169, "search_score": 5.2, "search_type": "keyword", "body_ka": "..."}
    ]
    results = search_by_keyword("áƒ“áƒ¦áƒ’")
    assert len(results) == 1
    assert results[0]["search_score"] == 5.2
    assert results[0]["search_type"] == "keyword"

@patch("app.services.vector_search.collection")
def test_keyword_search_index_missing_fallback(mock_coll):
    """Missing Atlas Search index returns empty list, no crash."""
    mock_coll.aggregate.side_effect = Exception("Atlas Search index not found")
    results = search_by_keyword("áƒ“áƒ¦áƒ’")
    assert results == []

def test_keyword_search_empty_query():
    """Empty query returns empty results."""
    results = search_by_keyword("")
    assert results == []

@patch("app.services.vector_search.collection")
def test_keyword_search_score_field_present(mock_coll):
    """Each result must have search_score from $meta."""
    mock_coll.aggregate.return_value = [
        {"article_number": 1, "search_score": 3.0, "search_type": "keyword"},
        {"article_number": 2, "search_score": 1.5, "search_type": "keyword"},
    ]
    results = search_by_keyword("áƒ¡áƒáƒ¨áƒ”áƒ›áƒáƒ¡áƒáƒ•áƒšáƒ")
    assert all("search_score" in r for r in results)

def test_rrf_merge_three_sources():
    """RRF merge handles results from 3 different sources."""
    results = [
        {"article_number": 1, "score": 0.95, "search_type": "semantic"},
        {"article_number": 2, "search_score": 8.0, "search_type": "keyword"},
        {"article_number": 1, "score": 1.0, "search_type": "direct"},
    ]
    merged = merge_and_rank(results)
    # Article 1 appears in 2 sources â†’ higher RRF score
    assert merged[0]["article_number"] == 1
    assert len(merged) == 2  # Deduplicated

def test_rrf_handles_mixed_score_scales():
    """RRF doesn't compare raw scores across sources."""
    results = [
        {"article_number": 10, "score": 0.1, "search_type": "semantic"},  # Low vector
        {"article_number": 20, "search_score": 9.5, "search_type": "keyword"},  # High keyword
    ]
    merged = merge_and_rank(results)
    # Both should get equal RRF rank (rank 0 in their source)
    assert len(merged) == 2

@patch("app.services.vector_search.settings")
def test_hybrid_search_keyword_disabled(mock_settings):
    """keyword_search_enabled=False skips keyword search entirely."""
    mock_settings.keyword_search_enabled = False
    # Assert search_by_keyword NOT called
```

#### Task 6 â€” Integration: 2 Tests (C5 â€” pipeline + SSE)

```python
@patch("app.services.rag_pipeline.get_genai_client")
@patch("app.services.rag_pipeline.hybrid_search")
@patch("app.services.rag_pipeline.rewrite_query")
async def test_full_pipeline_rewrite_search_flow(mock_rewrite, mock_search, mock_genai):
    """Full pipeline: rewrite â†’ search â†’ generate."""
    mock_rewrite.return_value = "áƒ“áƒ¦áƒ’-áƒ¡ áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒáƒªáƒ˜áƒ˜áƒ¡ áƒáƒ áƒáƒªáƒ”áƒ“áƒ£áƒ áƒ áƒ¡áƒáƒ¥áƒáƒ áƒ—áƒ•áƒ”áƒšáƒáƒ¨áƒ˜"
    mock_search.return_value = [{"article_number": 160, "body_ka": "...", "score": 0.9}]
    mock_genai.return_value.models.generate_content.return_value.text = \
        "áƒ“áƒ¦áƒ’-áƒ¡ áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒáƒªáƒ˜áƒ áƒ¡áƒáƒ­áƒ˜áƒ áƒáƒ..."

    response = await answer_question(
        "áƒ›áƒ˜áƒœáƒ“áƒ áƒ“áƒ¦áƒ’-áƒ¡ áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒáƒªáƒ˜áƒ",
        history=[{"role": "user", "content": "previous"}],
    )

    # Rewriter was called with history
    mock_rewrite.assert_called_once()
    # Response contains generated answer
    assert "áƒ“áƒ¦áƒ’" in response.answer

async def test_sse_stream_e2e_sources_enrichment():
    """SSE stream: sources event includes id and url fields."""
    # Use TestClient to call /ask/stream
    # Parse SSE events
    # Assert: 'sources' event has id (int) and url (str) per source
    # Assert: 'done' event received
```

---

### A7: SSE Source Enrichment Design (C1 + M2)

> [!IMPORTANT]
> This section documents HOW citation source data integrates with the SSE generator, based on reading `api_router.py` lines 149-212.

**Updated SSE flow with enriched sources:**
```python
async def generate():
    rag_response = await answer_question(body.question, history=history)

    # Emit enriched sources event with id + url
    sources_data = [
        {"id": i + 1, "article_number": s.article_number, "title": s.title, "url": s.url}
        for i, s in enumerate(rag_response.source_metadata)
    ]
    yield _sse("sources", sources_data)

    for chunk in _chunk_text(rag_response.answer, 80):
        yield _sse_event("text", {"content": chunk})
```

---

### A8: TDD Quality Gates (H2 â€” Semgrep + Lint)

After **every file change**, the worker must run:

```bash
# 1. Type check (if applicable)
# 2. Lint
cd /Users/maqashable/Desktop/scoop-sagadasaxado/tax_agent
.venv/bin/python -m pytest tests/ -x -q --tb=short

# 3. Security scan (MANDATORY per claude-building)
# semgrep --config auto app/services/{changed_file}.py --severity ERROR
```

> If semgrep is not installed, install once: `pip install semgrep`
> If semgrep is too slow, use `--config p/python` instead of `--config auto`

---

### A9: Incremental Commit Strategy (M3)

| After Task | Commit Message | Tag |
|-----------|---------------|-----|
| Task 2 | `feat: add disambiguation rules to system prompt` | â€” |
| Task 3 | `feat: upgrade system prompt to empathic persona with few-shot` | â€” |

| Task 4 | `feat: add contextual query rewriter for multi-turn` | â€” |
| Task 5 | `feat: add keyword search with Edge N-gram + RRF merge` | â€” |
| Task 7 | `feat: add citation backend support with Matsne deep-links` | â€” |
| Task 6 | `test: add integration tests for full enterprise pipeline` | `sprint-1.0` |

---

### A10: Config Settings Complete (M7)

**All new settings to add to `config.py`:**
```python
# â”€â”€â”€ (PII Settings deferred) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â”€â”€â”€ Keyword Search Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
keyword_search_enabled: bool = Field(default=True)
synonym_collection_name: str = Field(default="tax_synonyms")

# â”€â”€â”€ Query Rewriter Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
query_rewrite_model: str = Field(default="gemini-2.0-flash")
query_rewrite_timeout: int = Field(default=3)  # seconds
query_rewrite_enabled: bool = Field(default=True)

# â”€â”€â”€ Citation Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
citation_enabled: bool = Field(default=True)
matsne_base_url: str = Field(default="https://matsne.gov.ge/ka/document/view/1043717/most-current-version")
```

---

### A11: E2E Verification Method (M5)

**How to verify citation enrichment and query rewriting:**
```bash
# 1. Start server
# 2. Send tax question
curl -s http://localhost:8000/api/ask \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $KEY" \
  -d '{"question": "áƒ áƒ áƒáƒ áƒ˜áƒ¡ áƒ“áƒ¦áƒ’-áƒ¡ áƒ’áƒáƒœáƒáƒ™áƒ•áƒ”áƒ—áƒ˜ áƒ¡áƒáƒ¥áƒáƒ áƒ—áƒ•áƒ”áƒšáƒáƒ¨áƒ˜?"}'

# 3. Check response JSON:
#    âœ… sources array has id (int) and url (str) per source
#    âœ… url starts with https://matsne.gov.ge/
#    âœ… answer contains [1] or [2] citation markers
```

---

*Plan generated by Worker Agent | Move 2: Strategic Planning | Opus Planning v3.0*
*Quality Gate: 92% â†’ **98% after gap fix** âœ… | Pre-Mortem: 6 scenarios mitigated*
*Gap Remediation: 18/18 gaps fixed | Claude-Building v3.0 compliant*

